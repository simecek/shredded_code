<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Shredded Code</title>
    <link>/post/</link>
    <description>Recent content in Posts on Shredded Code</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 12 Nov 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Get S&amp;P500 data with pandas_datareader</title>
      <link>/2019/11/12/get-s-p500-data-with-pandas-datareader/</link>
      <pubDate>Tue, 12 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/11/12/get-s-p500-data-with-pandas-datareader/</guid>
      <description>import pandas as pd from pandas_datareader import data as wb Getting data # ^GSPC is code for S&amp;amp;P500, see https://finance.yahoo.com/quote/%5EGSPC/ ticker_name = &#39;^GSPC&#39; ticker = wb.DataReader(ticker_name, start=&#39;2010-1-1&#39;, data_source=&#39;yahoo&#39;) print(ticker)  High Low ... Volume Adj Close Date ... 2010-01-04 1133.869995 1116.560059 ... 3991400000 1132.989990 2010-01-05 1136.630005 1129.660034 ... 2491020000 1136.520020 2010-01-06 1139.189941 1133.949951 ... 4972660000 1137.140015 2010-01-07 1142.459961 1131.319946 ... 5270680000 1141.689941 2010-01-08 1145.390015 1136.219971 ... 4389590000 1144.979980 ... ... .</description>
    </item>
    
    <item>
      <title>Saving a list of variables together into a compressed file</title>
      <link>/2019/10/06/saving-a-list-of-variables-together-into-a-compressed-file/</link>
      <pubDate>Sun, 06 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/10/06/saving-a-list-of-variables-together-into-a-compressed-file/</guid>
      <description>In Python, there is no simple equivalent of R&#39;s save and save.image functions that would serialize a list of variables into a single compressed file. I have decided to change that.
import __main__ import pickle from bz2 import BZ2File from gzip import GzipFile from typing import Optional, List def save_env(path: str, objects: Optional[List[str]] = None, compress: str = &#39;gzip&#39;, protocol: int = -1): &amp;quot;&amp;quot;&amp;quot; Save the environment (list of objects) of Jupyter Notebook into a compressed file Args: path: path to the file objects: names of global objects to be saved compress: compression - default &#39;gzip&#39;, slower but better &#39;bz2&#39;, faster but much worse &#39;none&#39; protocol: pickle protocol version (-1 = latest) Inspired by https://stackoverflow.</description>
    </item>
    
    <item>
      <title>Time measuring decorator</title>
      <link>/2019/06/09/time-measuring-decorator/</link>
      <pubDate>Sun, 09 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/06/09/time-measuring-decorator/</guid>
      <description>This is an example how to write your own time measuring decorator.
import datetime from numpy.random import rand class time_decorator: def __init__(self, f): self.f = f print(f&amp;quot;Time decorator for {self.f.__name__} created&amp;quot;) def __call__(self, *args, **kwargs): start = datetime.datetime.now() result = self.f(*args, **kwargs) duration = datetime.datetime.now() - start print(f&amp;quot;Duration of {self.f.__name__} function call was {duration}.&amp;quot;) return result @time_decorator def sum_of_random_numbers(n): random_numbers = rand(n) return sum(random_numbers) Time decorator for sum_of_random_numbers created  sum_of_random_numbers(10_000_000) Duration of sum_of_random_numbers function call was 0:00:01.</description>
    </item>
    
    <item>
      <title>Valentine&#39;s Day</title>
      <link>/2019/02/14/valentine-s-dat/</link>
      <pubDate>Thu, 14 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/02/14/valentine-s-dat/</guid>
      <description>You can run the script by
python valentine.py.R
or
Rscript valentine.py.R
For Windows or Mac, please, change the line #5 as instructed.
 s = &#39;Python is awesome!&#39; red = &amp;quot;#FA5882&amp;quot; a = eval(&amp;quot;exec(&#39;import sys; import matplotlib.pyplot as plt; import numpy as np; print(s); t = np.arange(0,2*np.pi, 0.1); x = 16*np.sin(t)**3; y = 13*np.cos(t)-5*np.cos(2*t)-2*np.cos(3*t)-np.cos(4*t); plt.fill(x,y,color=red); plt.show(); sys.exit()&#39;)&amp;quot;) print(&#39;R is great too!&#39;) X11() # Use windows() or qartz() if on Windows or Mac t = seq(0, 2*pi, by=0.</description>
    </item>
    
    <item>
      <title>Set options to save all your data when the script crashes</title>
      <link>/2018/08/18/set-options-to-save-all-your-data-when-the-script-crashes/</link>
      <pubDate>Sat, 18 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/18/set-options-to-save-all-your-data-when-the-script-crashes/</guid>
      <description>If the running time of your R script is in hours and there is a danger of crash:
save_all &amp;lt;- function() { save.image(&amp;quot;recover.rda&amp;quot;) } options(error = save_all) I wish I discovered this before
&amp;quot;Error in pdf(...): failed to load default encoding&amp;quot; appeared on my screen.</description>
    </item>
    
    <item>
      <title>R Magic In Jupyter Notebooks</title>
      <link>/2017/04/03/r-magic-in-jupyter-notebooks/</link>
      <pubDate>Mon, 03 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/04/03/r-magic-in-jupyter-notebooks/</guid>
      <description>How to add R code to your (IPython) Jupyter Notebook. The notebook can be accessed from Github.
%load_ext rpy2.ipython import warnings warnings.filterwarnings(&amp;#39;ignore&amp;#39;) %R require(ggplot2); require(tidyr) array([1], dtype=int32)  import numpy as np import pandas as pd np.random.seed(42) # Make a pandas DataFrame df = pd.DataFrame(np.random.normal(0,1,size=(100, 3)), columns=list(&amp;#39;ABC&amp;#39;)) df[&amp;#39;C&amp;#39;] = df[&amp;#39;C&amp;#39;] + 2 %%R -i df df %&amp;gt;% gather(&amp;#34;Category&amp;#34;, &amp;#34;X&amp;#34;) %&amp;gt;% ggplot(aes(x = Category, y = X, fill = Category)) + geom_violin() + stat_summary(fun.</description>
    </item>
    
    <item>
      <title>Tweeting With Tweepy</title>
      <link>/2017/03/31/tweeting-with-tweepy/</link>
      <pubDate>Fri, 31 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/03/31/tweeting-with-tweepy/</guid>
      <description>How to manage your Twitter account with Python. The notebook can be accessed from Github.
Function: Get List Of Users That Liked A Status # copied from http://stackoverflow.com/questions/28982850/twitter-api-getting-list-of-users-who-favorited-a-status import urllib2 import re def get_user_ids_of_post_likes(post_id): try: json_data = urllib2.urlopen(&amp;#39;https://twitter.com/i/activity/favorited_popup?id=&amp;#39; + str(post_id)).read() found_ids = re.findall(r&amp;#39;data-user-id=\\&amp;#34;+\d+&amp;#39;, json_data) unique_ids = list(set([re.findall(r&amp;#39;\d+&amp;#39;, match)[0] for match in found_ids])) return unique_ids except urllib2.HTTPError: return False # Example:  # https://twitter.com/golan/status/731770343052972032 print get_user_ids_of_post_likes(731770343052972032) # [&amp;#39;13520332&amp;#39;, &amp;#39;416273351&amp;#39;, &amp;#39;284966399&amp;#39;] # # 13520332 +&amp;gt; @TopLeftBrick # 416273351 =&amp;gt; @Berenger_r # 284966399 =&amp;gt; @FFrink [&#39;472203302&#39;, &#39;13520332&#39;, &#39;2388203390&#39;, &#39;732265223701286912&#39;, &#39;416273351&#39;, &#39;6490642&#39;, &#39;284966399&#39;]  Connect to Twitter with Tweepy import tweepy # create file twkeys.</description>
    </item>
    
    <item>
      <title>Data Science Amazon VM With Start/Stop Functionality</title>
      <link>/2017/02/17/data-science-amazon-vm-with-start/stop-functionality/</link>
      <pubDate>Fri, 17 Feb 2017 23:19:03 -0500</pubDate>
      
      <guid>/2017/02/17/data-science-amazon-vm-with-start/stop-functionality/</guid>
      <description>Jeff Leek has tried to move to the cloud with his Chromebook Experiment.
My motivation is different but my goal is similar. Would it be possible to create a virtual machine (VM) in the cloud that after an initial setting&amp;hellip;
  It can be started/stopped from the web browser (you do not need SSH into it). Ideally, I also want a command line client to start/stop VM.
  It has RStudio / Jupyter Notebook that starts/stops with the machine.</description>
    </item>
    
    <item>
      <title>Microsoft Face API</title>
      <link>/2017/01/28/microsoft-face-api/</link>
      <pubDate>Sat, 28 Jan 2017 23:52:09 -0500</pubDate>
      
      <guid>/2017/01/28/microsoft-face-api/</guid>
      <description>Before you start, you need to register at Microsoft Cognitive Services and ask for a free trial. Copy Face-Preview API key into an environment variable faceKEY as follows Sys.setenv(faceKEY = &amp;quot;***YOUR*KEY***&amp;quot;). Here, I will demonstrate Face API on my Twitter profile picture:
 library(httr) faceURL = &amp;quot;https://westus.api.cognitive.microsoft.com/face/v1.0/detect?returnFaceAttributes=age,gender,smile,facialHair&amp;quot; img.url = &amp;quot;https://pbs.twimg.com/profile_images/420950459289833472/JtRoD1cw_400x400.jpeg&amp;quot; faceKEY = Sys.getenv(&amp;quot;faceKEY&amp;quot;) mybody = list(url = img.url) faceResponse = POST( url = faceURL, content_type(&amp;#39;application/json&amp;#39;), add_headers(.headers = c(&amp;#39;Ocp-Apim-Subscription-Key&amp;#39; = faceKEY)), body = mybody, encode = &amp;#39;json&amp;#39; ) # status ok = 200 faceResponse$status ## [1] 401 All information about a picture is now easily accesible by applying the function content.</description>
    </item>
    
    <item>
      <title>Interactive Graphs With Plotly And Ggiraph Packages</title>
      <link>/2017/01/26/interactive-graphs-with-plotly-and-ggiraph-packages/</link>
      <pubDate>Thu, 26 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/01/26/interactive-graphs-with-plotly-and-ggiraph-packages/</guid>
      <description>Imagine that you have a plot like this and want to make it interactive (e.g.Â show exact values on hover or print the model name).
suppressPackageStartupMessages(library(ggplot2)) p &amp;lt;- ggplot(mpg, aes(displ, hwy, color=class)) + geom_point() + labs(title=&amp;quot;Smaller car = better MPG&amp;quot;, subtitle=&amp;quot;Fuel economy data from 1999 and 2008 for 38 popular models of car&amp;quot;, caption = &amp;quot;adapted from http://fueleconomy.gov&amp;quot;, x=&amp;quot;engine displacement (l)&amp;quot;, y=&amp;quot;highway (miles per gallon)&amp;quot;) print(p) Plotly Getting plotly of this graph is just one-liner.</description>
    </item>
    
    <item>
      <title>Census data animated</title>
      <link>/2016/03/01/census-data-animated/</link>
      <pubDate>Tue, 01 Mar 2016 00:00:00 +0000</pubDate>
      
      <guid>/2016/03/01/census-data-animated/</guid>
      <description>I just adapted the code from here to harvest Czech Republic population estimates.
library(idbr) # devtools::install_github(&amp;#39;walkerke/idbr&amp;#39;) library(ggplot2) library(animation) library(dplyr) library(ggthemes) idb_api_key(&amp;#34;YOUR API CODE HERE&amp;#34;) male &amp;lt;- idb1(&amp;#39;EZ&amp;#39;, 2000:2050, sex = &amp;#39;male&amp;#39;) %&amp;gt;% mutate(POP = POP * -1, SEX = &amp;#39;Male&amp;#39;) female &amp;lt;- idb1(&amp;#39;EZ&amp;#39;, 2000:2050, sex = &amp;#39;female&amp;#39;) %&amp;gt;% mutate(SEX = &amp;#39;Female&amp;#39;) czechrep &amp;lt;- rbind(male, female) %&amp;gt;% mutate(abs_pop = abs(POP)) # Animate it with a for loop saveGIF({ for (i in 2000:2050) { title &amp;lt;- as.</description>
    </item>
    
    <item>
      <title>Animated ggplots with gganimate</title>
      <link>/2016/02/19/animated-ggplots-with-gganimate/</link>
      <pubDate>Fri, 19 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>/2016/02/19/animated-ggplots-with-gganimate/</guid>
      <description>There is now an easy way to create an animated GIF with gganimate package:
library(gapminder) library(ggplot2) library(gganimate) theme_set(theme_bw()) p &amp;lt;- ggplot(gapminder, aes(gdpPercap, lifeExp, size = pop, color = continent, frame = year)) + geom_point() + scale_x_log10() gg_animate(p) See that all you need to do is to set frame variable. A more sophisticated example from David Robinson.
library(dplyr) library(ggplot2) library(broom) library(gganimate) theme_set(theme_bw()) set.seed(2016) min_weight &amp;lt;- .0005 # original data and bandwidths bws &amp;lt;- c(.</description>
    </item>
    
    <item>
      <title>Docker One-liners</title>
      <link>/2016/02/18/docker-one-liners/</link>
      <pubDate>Thu, 18 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>/2016/02/18/docker-one-liners/</guid>
      <description>Let other people care about the installation procedures. The best thing about docker is that you get your app installed and running with just one line of code. I am listing here my favorite docker images and one-liners to run them.
My favorite way to run docker containers is a virtual machine on Digital Ocean with Ubuntu and docker preinstalled (see &amp;lsquo;How to start Digital Ocean droplet?&amp;rsquo; here ).
RStudio Server I use rocker/hadleyverse docker image</description>
    </item>
    
    <item>
      <title>Stop And Remove All Containers</title>
      <link>/2016/01/30/stop-and-remove-all-containers/</link>
      <pubDate>Sat, 30 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>/2016/01/30/stop-and-remove-all-containers/</guid>
      <description>If you want to stop all your running docker containers, use
docker stop $(docker ps -a -q) Stopped containers can be restarted with docker start command or they can be removed permanently with
docker rm $(docker ps -a -q) </description>
    </item>
    
    <item>
      <title>Log Into A Running Docker Container</title>
      <link>/2016/01/26/log-into-a-running-docker-container/</link>
      <pubDate>Tue, 26 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>/2016/01/26/log-into-a-running-docker-container/</guid>
      <description>Imagine your container is running but you would like to &amp;ldquo;ssh inside&amp;rdquo;. For example your container is R/Shiny server and you need to install a new R package. Or your container is Jupyter Notebook and your forgot the password to access it (it is stored in the environment variable $PASSWORD).
You need a way to log into the container. And the following command is doing exactly that:
docker exec -i -t $CONTAINERID /bin/bash where $CONTAINERID is a hexadecimal number you get from docker ps listing, e.</description>
    </item>
    
  </channel>
</rss>